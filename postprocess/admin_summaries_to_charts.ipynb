{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prompt-grounds",
   "metadata": {},
   "source": [
    "# Post-process ADM1 summary results\n",
    "\n",
    "For loading in oi-risk-vis interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_fnames = glob('../results/*/Cyclone/*.csv')\n",
    "fluvial_fnames = glob('../results/*/Fluvial/*/*.csv')\n",
    "coastal_fnames = glob('../results/*/Coastal/*/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = set()\n",
    "for fname in tqdm(cyclone_fnames):\n",
    "    df = pd.read_csv(fname, nrows=1)\n",
    "    cols = cols | set(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-newfoundland",
   "metadata": {},
   "source": [
    "## Cyclone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for fname in tqdm(cyclone_fnames):    \n",
    "    sector = os.path.basename(os.path.dirname(os.path.dirname(fname)))\n",
    "    df = pd.read_csv(fname)\n",
    "    df['sector'] = sector\n",
    "    dfs.append(df)\n",
    "cyclone = pd.concat(dfs).set_index(['sector','region_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df_by_rp_columns(df):\n",
    "    df_rp = df[[c for c in df.columns if 'RP' in c]]\n",
    "    df_exp = df[[c for c in df.columns if 'RP' not in c]]\n",
    "    return df_rp, df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-eating",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_rp, cyclone_exp = split_df_by_rp_columns(cyclone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_df(df, id_vars, new_id_vars):\n",
    "    # melt to get a long dataframe with \"variable\" and \"value\"\n",
    "    # columns, where \"variable\" is taken from each input column name\n",
    "    df_tidy = df \\\n",
    "        .reset_index() \\\n",
    "        .melt(id_vars=id_vars)\n",
    "    \n",
    "    # create a column from each new_id_var \n",
    "    # by splitting the \"variable\" names on \"_\"\n",
    "    for i, varname in enumerate(new_id_vars):\n",
    "        df_tidy[varname] = df_tidy.variable.apply(lambda d: d.split(\"_\")[i+1])\n",
    "        \n",
    "    # keep only the first element as the actual variable name \n",
    "    df_tidy['variable'] = df_tidy.variable.apply(lambda d: d.split(\"_\")[0])\n",
    "    \n",
    "    # parse an integer from return period, if present\n",
    "    if 'rp' in new_id_vars:\n",
    "        df_tidy.rp = df_tidy.rp.apply(lambda d: int(d.replace(\"RP\", \"\")))\n",
    "        \n",
    "    # pivot back out to columns for each variable\n",
    "    df_tidy = df_tidy.pivot_table(index=(id_vars + new_id_vars), columns='variable')\n",
    "    df_tidy.columns = [v for _, v in df_tidy.columns]\n",
    "    return df_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_rp_tidy = tidy_df(\n",
    "    cyclone_rp, id_vars=['region_name', 'sector'], new_id_vars=['hazard', 'rp'])\n",
    "cyclone_rp_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_exp_tidy = tidy_df(cyclone_exp, id_vars=['region_name', 'sector'], new_id_vars=['hazard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_exp_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_rp_tidy.to_csv('../results/cyclone_rp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclone_exp_tidy.to_csv('../results/cyclone_exp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broken-thanks",
   "metadata": {},
   "source": [
    "## Flooding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = defaultdict(list)\n",
    "for fname in tqdm(fluvial_fnames):\n",
    "    climate = os.path.basename(os.path.dirname(fname))\n",
    "    sector = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(fname))))\n",
    "    df = pd.read_csv(fname)\n",
    "    df['sector'] = sector\n",
    "    df['rcp'] = climate\n",
    "    dfs[climate].append(df)\n",
    "fluvial_hist = pd.concat(dfs['historical']).set_index(['region_name','sector','rcp'])\n",
    "fluvial_fut  = pd.concat(dfs['rcp4p5'] + dfs['rcp8p5']).set_index(['region_name','sector','rcp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_fut_rp, fluvial_fut_exp = split_df_by_rp_columns(fluvial_fut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_fut_exp_tidy = tidy_df(\n",
    "    fluvial_fut_exp, \n",
    "    id_vars=['region_name', 'sector', 'rcp'],\n",
    "    new_id_vars=['gcm', 'epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_fut_exp_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_fut_rp_tidy = tidy_df(\n",
    "    fluvial_fut_rp, \n",
    "    id_vars=['region_name', 'sector', 'rcp'],\n",
    "    new_id_vars=['gcm', 'epoch', 'rp'])\n",
    "fluvial_fut_rp_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_hist_rp, fluvial_hist_exp = split_df_by_rp_columns(fluvial_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_hist_exp_tidy = tidy_df(\n",
    "    fluvial_hist_exp, \n",
    "    id_vars=['region_name', 'sector', 'rcp'],\n",
    "    new_id_vars=['gcm', 'epoch'])\n",
    "\n",
    "fluvial_hist_exp_tidy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-environment",
   "metadata": {},
   "outputs": [],
   "source": [
    "fluvial_hist_rp_tidy = tidy_df(\n",
    "    fluvial_hist_rp, \n",
    "    id_vars=['region_name', 'sector', 'rcp'],\n",
    "    new_id_vars=['gcm', 'epoch', 'rp'])\n",
    "fluvial_hist_rp_tidy.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
